				Hadoop Installation
http://www.vmware.com/products/workstation/workstation-evaluation.html?downloadGroup=WKST-1112-WIN

http://www.tautrader.net/tool/vm/ubuntu1604t.html

sudo apt-get install update
sudo apt-get install default-jdk

# This is to install java jvm in ubuntu machine

sudo apt-get install openjdk-8-jdk
/usr/lib/jvm/jdk
http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
=============================================

https://archive.apache.org/dist/hadoop/core/hadoop-2.6.0/

Create work folder in home and copy downloaded Hadoop folder

tar -xvzf hadoop-2.6.0.tar.gz
============================d=================
Enter into Hadoop untarred file
cd work
cd hadoop-2.6.0
cd etc
cd hadoop
ls
sudo nano hadoop-env.sh

Specify Java path 
JAVA_HOME=/usr/lib/jvm/jdk

=============================================
Open core-site.xml
sudo nano core-site.xml
<property>
   <name>fs.default.name</name>
   <value>hdfs://localhost:9000</value>
</property>
===============================================
sudo nano hdfs-site.xml
<property>
    <name>fs.replication</name>
    <value>1</value>
</property>
<property>
    <name>dfs.namenode.name.dir</name>
    <value>/home/Bigdata/work/hdfs/namenode</value>
</property>
<property>
    <name>dfs.datanode.data.dir</name>
    <value>/home/Bigdata/work/hdfs/datanode</value>
</property>
================================================
Hadoop-1.x - Jobtracker - Tasktracker
Hadoop-2.x - resourcemanager - nodemanager - YARN - Yet Another Resource Negotiator
================================================
sudo nano yarn-site.xml yet another resource negotiator
<property>
   <name>yarn.nodemanager.aux-services</name>
   <value>mapreduce_shuffle</value>
</property>
<property>
     <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
     <value>org.apache.hadoop.mapred.shuffleHandler</value>
</property>
================================================
Rename mapred-site.xml.template to 
mapred-site.xml

<configuration>
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
<property>
	<name>mapred.jobtracker.taskscheduler</name>
	<value>org.apache.hadoop.mapred.FairScheduler</value>
</property>
</configuration>

================================================
sudo nano ~/.bashrc

export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/home/yarn/work/hadoop-2.6.0

export PATH=$JAVA_HOME/bin:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH

Compile bashrc with the following command
source ~/.bashrc
==================================================================

sudo apt-get install openssh-client
sudo apt-get install openssh-server

ssh-keygen -t rsa -P ""

cat .ssh/id_rsa.pub>>.ssh/authorized_keys

ssh localhost
Type exit  -  connection to localhost closed
=============================================

hadoop namenode -format
start-all.sh
jps
stop-all.sh

==================================================================
PIG - Installation
Download PIG from the following link
https://archive.apache.org/dist/pig/pig-0.14.0/
set bashrc path
sudo nano ~/.bashrc
export PIG_HOME=/home/Bigdata/pig-0.14.0/
export PATH=$PIG_HOME/bin
===============================================
mr-jobhistory-daemon.sh stop historyserver
mr-jobhistory-daemon.sh start historyserver
===============================================
---------------------------------------------------------------------------------------------------------------------------------------
This is for Cloudera VMware

Download vm player from http://www.vmware.com/support/download-player   
HADOOP vm from cloudera can be downloaded from  http://content.udacity-data.com/courses/ud617/Cloudera-Udacity-Training-VM-4.1.1.c.zip
HADOOP has introduced several versions the vm image present in the following link is 0.18 version of HADOOP http://developer.yahoo.com/hadoop/tutorial/module3.html  
Download putty from http://www.putty.org/  and winscp http://winscp.net/eng/download.php 
---------------------------------------------------------------------------------------------------------------------------------------

HIVE INSTALATION
------------------
hive installation steps

1.Start by downloading the most recent stable release of hive from one of the apache download mirror through the browser(for ex hive-0.14.0.tar.gz).

https://archive.apache.org/dist/hive/hive-0.14.0/
				
2. copy the hive tar file into work folder

3.~$tar -xzf hive-0.14.0.tar.gz

4.set the environmental variable HIVE_HOME in bashrc file.

export HIVE_HOME=/home/Bigdata/work/apache-hive-0.14.0-bin
export PATH=$PATH:$HIVE_HOME/bin;
===================================================================
Rename hive-env.sh.template to hive-env.sh
export HADOOP_HEAPSIZE=1024
export HADOOP_HOME=/home/Bigdata/work/hadoop-2.6.0
export HIVE_CONF_DIR=/home/Bigdata/work/apache-hive-0.14.0-bin/conf
===================================================================
Rename hive-default.xml.template to hive-site.xml
<configuration>
<property>
	<name>javax.jdo.option.ConnectionURL</name>
	<value>jdbc:derby:;databaseName=/home/Bigdata/work/apache-hive-0.14.0-bin/metastore_db;create=true</value>
	<description>
	JDBC connect string for a JDBC metastore.
To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
	For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
	</description>
</property>

<property>
	<name>hive.metastore.warehouse.dir</name>
	<value>/home/Bigdata/work/hive/warehouse</value>
	<description>location of default database for the warehouse</description>
</property>

<property>
	<name>hive.metastore.local</name>
	<value>true</value>
	<description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
</property>

<property>
	<name>javax.jdo.option.ConnectionDriverName</name>
	<value>org.apache.derby.jdbc.EmbeddedDriver</value>
	<description>Driver class name for a JDBC metastore</description>
</property>

<property>
	<name>javax.jdo.PersistenceManagerFactoryClass</name>
	<value>org.datanucleus.api.jdo.JDOPersistenceManagerFactory</value>
	<description>class implementing the jdo persistence</description>
</property>

</configuration>
============================================================================
To Configure mysql  as a metastore
steps
$mysql -u root -p
Enter password:
mysql>create database metastore_db


create a new user in  MySQL 
CREATE USER 'matuser'@'hp-Satellite-A505' IDENTIFIED BY 'matuser';

mysql>GRANT ALL PRIVILEGES on metastore_db.* to matuser@'hp-Satellite-A505' 


then go to hive_site.xml and modify following properties to communicate with mysql
<property> 
  <name>javax.jdo.option.ConnectionURL</name> 
  <value>jdbc:mysql://localhost:3306/metastore_db</value> 
  <description>JDBC connect string for a JDBC metastore</description> 
</property> 

<property> 
  <name>javax.jdo.option.ConnectionDriverName</name> 
  <value>com.mysql.jdbc.Driver</value> 
  <description>Driver class name for a JDBC metastore</description> 
</property> 

<property> 
  <name>javax.jdo.option.ConnectionUserName</name> 
  <value>matuser</value> 
  <description>username to use against metastore database</description> 
</property> 

<property> 
  <name>javax.jdo.option.ConnectionPassword</name> 
  <value>matuser</value> 
  <description>password to use against metastore database</description> 
</property> 


To enter into hive  	
user@master:~$hive
hive>
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------
Step 8: Verifying Hive Installation

On successful installation of Hive, you get to see the following response:

Logging initialized using configuration in jar:file:/home/hadoop/hive-0.9.0/lib/hive-common-0.9.0.jar!/hive-log4j.properties 
Hive history file=/tmp/hadoop/hive_job_log_hadoop_201312121621_1494929084.txt
………………….
hive>

-----------------------------------------------------------------------------------------------------------------------------------------------
The following sample command is executed to display all the tables:

hive> show tables; 
OK 
Time taken: 2.798 seconds 
hive>
===================================================================================



					Details
SSH Keys
SSH keys allow authentication between two hosts without the need of a password. SSH key authentication uses two keys, a private key and a publickey.
To generate the keys, from a terminal prompt enter:
ssh-keygen -t rsa
This will generate the keys using the RSA Algorithm. During the process you will be prompted for a password. Simply hit Enter when prompted to create the key.
By default the public key is saved in the file ~/.ssh/id_rsa.pub, while ~/.ssh/id_rsa is the private key. Now copy the id_rsa.pub file to the remote host and append it to ~/.ssh/authorized_keys by entering:
ssh-copy-id username@remotehost
Finally, double check the permissions on the authorized_keys file, only the authenticated user should have read and write permissions. If the permissions are not correct change them by:
chmod 600 .ssh/authorized_keys
You should now be able to SSH to the host without being prompted for a password.

Sudo apt-get

The apt-get command is a powerful command-line tool, which works with Ubuntu's Advanced Packaging Tool (APT) performing such functions as installation of new software packages, upgrade of existing software packages, updating of the package list index, and even upgrading the entire Ubuntu system.
Being a simple command-line tool, apt-get has numerous advantages over other package management tools available in Ubuntu for server administrators. Some of these advantages include ease of use over simple terminal connections (SSH), and the ability to be used in system administration scripts, which can in turn be automated by the cron scheduling utility.
Some examples of popular uses for the apt-get utility:


1. Update the Package Index: The APT package index is essentially a database of available packages from the repositories defined in the/etc/apt/sources.list file and in the /etc/apt/sources.list.d directory. To update the local package index with the latest changes made in the repositories, type the following:
2. sudo apt-get update


Installation
Installation of the OpenSSH client and server applications is simple. To install the OpenSSH client applications on your Ubuntu system, use this command at a terminal prompt:
sudo apt-get install openssh-client
To install the OpenSSH server application, and related support files, use this command at a terminal prompt:
sudo apt-get install openssh-server
The openssh-server package can also be selected to install during the Server Edition installation process.


SSH Keys
SSH keys allow authentication between two hosts without the need of a password. SSH key authentication uses two keys, a private key and a publickey.
To generate the keys, from a terminal prompt enter:
ssh-keygen -t rsa
This will generate the keys using the RSA Algorithm. During the process you will be prompted for a password. Simply hit Enter when prompted to create the key.
By default the public key is saved in the file ~/.ssh/id_rsa.pub, while ~/.ssh/id_rsa is the private key. Now copy the id_rsa.pub file to the remote host and append it to ~/.ssh/authorized_keys by entering:
ssh-copy-id username@remotehost
Finally, double check the permissions on the authorized_keys file, only the authenticated user should have read and write permissions. If the permissions are not correct change them by:
chmod 600 .ssh/authorized_keys
You should now be able to SSH to the host without being prompted for a password.

PIG Installation
---------------------------------
mapred-site.xml

<property>
  <name>mapreduce.jobhistory.address</name>
  <value>hp-Satellite-A505:10020</value>
  <description>Host and port for Job History Server (default 0.0.0.0:10020)</de$
</property>



